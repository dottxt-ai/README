<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="The .txt team" />
  <meta name="dcterms.date" content="2024-08-26" />
  <title>README</title>
  <link rel="stylesheet" href="reset.css" />
  <link rel="stylesheet" href="index.css" />
</head>
<body>
<table class="header">
  <tr>
    <td colspan="2" rowspan="2" class="width-auto">
      <h1 class="title">README</h1>
      <span class="subtitle">The Next Generation</span>
    </td>
  </tr>
  <tr>
  </tr>
  <tr>
    <th class="width-min">Author</th>
    <td class="width-auto"><a href="https://www.dottxt.co"><cite>The
.txt team</cite></a></td>
  </tr>
</table>
<p><img src="aspen.png" /></p>
<p>There are hidden rules in every system.</p>
<p>Rules to govern the sentences we write, the software we code, and the
music we play. These rules aren’t created to subjugate, but to
integrate. Without them, the different parts of a system can’t work
together to form something greater.</p>
<p>Some believe that these rules reflect our unique way of thinking and
conceiving of the world. But to computers alike, without structure there
is chaos. Raw text, out of order, doesn’t make a program. You need a
grammar — a syntax — to make the system work.</p>
<p>For almost a century, we’ve been teaching our machines the grammars
of our world to help us work, play, and create better. But as of yet,
our AIs remain stubbornly resistant to learning them. As smart as they
appear to be, we haven’t found a way to make their outputs predictable
(and thus useful) as part of a system. <em>It’s their fundamental
flaw.</em></p>
<p>We believe that this demands a new programming language, which allows
LLMs to respond in a way that software understands. Until then, our
generations are fun… but not transformative. Until then, it’s just the
beginning for how AI will change our world.</p>
<hr>
<p>Our mission is to help AI speak the language of every application</p>
<hr>
<p>.txt is a way to make LLMs reliable enough for the world to build on.
A spellcheck for programming the future. And more broadly… an ecosystem
for developers to design, execute, deploy, and evaluate LLM
applications.</p>
<p>Most businesses aren’t run on natural language. If your goal is to
sound conversational and believable enough, the everyday language works
just fine. But to be good enough to compute with, the level of clarity
must be far higher. In this sense, LLMs are, ironically, a
regression!</p>
<p>LLMs are probabilistic by nature. We believe the only solution is
implementing guard rails at the outset, based on your unique
criteria… taking all potential probabilities and setting all the useless
ones to zero. In other words, .txt stops LLM before they even make an
error.</p>
<p>Fewer tokens. Less money. More efficiency.</p>
<p>We cut our teeth in applied statistical modeling — a job where you
make bespoke models specially designed to give only correct answers. To
us, applying this field to LLMs is the logical next step. The missing
<em>layer</em> that will make AI truly useful.</p>
<p>The thing that makes LLMs act like… computers. Finally.</p>
<h1 id="section"></h1>
<ul class="incremental">
<li>Remi, Brandon and Dan</li>
</ul>
  <div class="debug-grid"></div>
  <script src="index.js"></script>
</body>
</html>
